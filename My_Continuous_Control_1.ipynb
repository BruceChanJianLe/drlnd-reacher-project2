{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# udacity virtual machine?\n",
    "vm_ = False\n",
    "if vm_:\n",
    "    # select version 1 (with a single agent) of the environment\n",
    "    env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "else:\n",
    "    env = UnityEnvironment(file_name='data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n",
    "\n",
    "# Useful Functions\n",
    "\n",
    "def act(env, actions, brain_name=\"ReacherBrain\") -> tuple:\n",
    "    \"\"\"Sends actions to the environment env and observes the results.\n",
    "    Returns a tuple of rewards, next_states, dones (One per agent)\"\"\"\n",
    "    action_result = env.step(actions)[brain_name] # Act on the environment and observe the result\n",
    "    return (action_result.rewards,\n",
    "            action_result.vector_observations, # next states\n",
    "            action_result.local_done) # True if the episode ended\n",
    "    \n",
    "def reset(env, training=True, brain_name=\"ReacherBrain\") -> np.ndarray:\n",
    "    \"\"\"Resetting the unity environment\"\"\"\n",
    "    return env.reset(train_mode=training)[brain_name].vector_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Ready for training\n",
    "\n",
    "In the next code cell, we shall start our preparation for training\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invite our agent & import torch\n",
    "from ddpg_agent import Agent\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(agent, env, num_episodes, log_freq, max_t=20000):        \n",
    "    score_hist = np.zeros((num_agents, 1))\n",
    "    \n",
    "    # Train\n",
    "    for i in range(num_episodes):\n",
    "        states = reset(env)\n",
    "        scores = np.zeros(num_agents)\n",
    "        for j in range(max_t): # Safer than while\n",
    "            # Decide\n",
    "            #state = states.squeeze() # One agent only\n",
    "            actions = agent.act(states)  # Choose an action based on the state\n",
    "            #actions = np.expand_dims(action, 0) # One agent only\n",
    "            # Act\n",
    "            rewards, next_states, dones = act(env, actions)     # Send the actions to the environment\n",
    "            scores += rewards                         # update the score (for each agent)\n",
    "            # Learn\n",
    "            agent.step(states, actions, rewards[0], next_states[0], dones[0]) # Learn step\n",
    "            # Step\n",
    "            states = next_states                               # roll over states to next time step\n",
    "            # Exit\n",
    "            if np.any(dones):                                  # exit loop if episode finished\n",
    "                break       \n",
    "        # Logging\n",
    "        score_hist = np.concatenate((score_hist, scores[:, None]), axis=1)\n",
    "        if (i % log_freq == 0) and (i > 0):\n",
    "            print(f'Average score of episodes {i-log_freq+1}-{i+1}: {np.mean(score_hist.squeeze()[-log_freq:])}')\n",
    "        \n",
    "        if np.mean(score_hist.squeeze()[-100:]) >= 30:\n",
    "            print(f'Solved in {i} steps!')\n",
    "            break\n",
    "            \n",
    "    return score_hist.squeeze()\n",
    "\n",
    "def train(agent, env, num_episodes, log_freq, max_t=20000):        \n",
    "    score_hist = np.zeros((num_agents, 1))\n",
    "    \n",
    "    # Train\n",
    "    for i in range(num_episodes):\n",
    "        states = reset(env)\n",
    "        agent.reset()\n",
    "        scores = np.zeros(num_agents)\n",
    "        for j in range(max_t): # Safer than while\n",
    "            # Decide\n",
    "            #state = states.squeeze() # One agent only\n",
    "            actions = agent.act(states)  # Choose an action based on the state\n",
    "            #actions = np.expand_dims(action, 0) # One agent only\n",
    "            # Act\n",
    "            rewards, next_states, dones = act(env, actions)     # Send the actions to the environment\n",
    "            scores += rewards                         # update the score (for each agent)\n",
    "            # Learn\n",
    "            agent.step(states, actions, rewards[0], next_states[0], dones[0]) # Learn step\n",
    "            # Step\n",
    "            states = next_states                               # roll over states to next time step\n",
    "            # Exit\n",
    "            if np.any(dones):                                  # exit loop if episode finished\n",
    "                break       \n",
    "        # Logging\n",
    "        score_hist = np.concatenate((score_hist, scores[:, None]), axis=1)\n",
    "        if (i % log_freq == 0) and (i > 0):\n",
    "            print(f'Average score of episodes {i-log_freq+1}-{i+1}: {np.mean(score_hist.squeeze()[-log_freq:])}')\n",
    "        \n",
    "        if np.mean(score_hist.squeeze()[-100:]) >= 30:\n",
    "            print(f'Solved in {i} steps!')\n",
    "            break\n",
    "            \n",
    "    return score_hist.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score of episodes 1-11: 0.39699999112635853\n",
      "Average score of episodes 11-21: 0.9329999791458249\n",
      "Average score of episodes 21-31: 1.3769999692216515\n",
      "Average score of episodes 31-41: 2.378999946825206\n",
      "Average score of episodes 41-51: 1.9829999556764961\n",
      "Average score of episodes 51-61: 2.922999934665859\n",
      "Average score of episodes 61-71: 3.2439999274909495\n",
      "Average score of episodes 71-81: 2.9949999330565333\n",
      "Average score of episodes 81-91: 3.756999916024506\n",
      "Average score of episodes 91-101: 3.2439999274909495\n",
      "Average score of episodes 101-111: 4.675999895483256\n",
      "Average score of episodes 111-121: 5.257999882474541\n",
      "Average score of episodes 121-131: 6.1989998614415525\n",
      "Average score of episodes 131-141: 5.4069998791441325\n",
      "Average score of episodes 141-151: 6.585999852791429\n",
      "Average score of episodes 151-161: 7.516999831981957\n",
      "Average score of episodes 161-171: 8.865999801829457\n",
      "Average score of episodes 171-181: 6.510999854467809\n",
      "Average score of episodes 181-191: 8.31899981405586\n",
      "Average score of episodes 191-201: 9.217999793961644\n",
      "Average score of episodes 201-211: 7.780999826081097\n",
      "Average score of episodes 211-221: 7.8369998248294\n",
      "Average score of episodes 221-231: 8.708999805338681\n",
      "Average score of episodes 231-241: 9.164999795146286\n",
      "Average score of episodes 241-251: 12.013999731466175\n",
      "Average score of episodes 251-261: 11.672999739088118\n",
      "Average score of episodes 261-271: 8.574999808333814\n",
      "Average score of episodes 271-281: 13.200999704934656\n",
      "Average score of episodes 281-291: 12.41899972241372\n",
      "Average score of episodes 291-301: 11.108999751694501\n",
      "Average score of episodes 301-311: 10.462999766133725\n",
      "Average score of episodes 311-321: 14.647999672591686\n",
      "Average score of episodes 321-331: 11.466999743692577\n",
      "Average score of episodes 331-341: 13.012999709136784\n",
      "Average score of episodes 341-351: 10.902999756298959\n",
      "Average score of episodes 351-361: 12.310999724827706\n",
      "Average score of episodes 361-371: 11.445999744161963\n",
      "Average score of episodes 371-381: 12.645999717339873\n",
      "Average score of episodes 381-391: 9.713999782875181\n",
      "Average score of episodes 391-401: 12.397999722883105\n",
      "Average score of episodes 401-411: 13.506999698095024\n",
      "Average score of episodes 411-421: 17.63099960591644\n",
      "Average score of episodes 421-431: 13.151999706029892\n",
      "Average score of episodes 431-441: 15.350999656878411\n",
      "Average score of episodes 441-451: 15.46699965428561\n",
      "Average score of episodes 451-461: 15.224999659694731\n",
      "Average score of episodes 461-471: 15.527999652922153\n",
      "Average score of episodes 471-481: 15.972999642975628\n",
      "Average score of episodes 481-491: 16.06399964094162\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(state_size, action_size, np.random.randint(1e5))\n",
    "score_hist = train(agent, env, num_episodes=500, log_freq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.font_manager:Generating new fontManager, this may take some time...\n",
      "INFO:matplotlib.font_manager:Failed to extract font properties from /usr/share/fonts/truetype/noto/NotoColorEmoji.ttf: In FT2Font: Can not load face.  Unknown file format.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(signal:np.ndarray , period: int):\n",
    "    buffer = [np.nan] * period\n",
    "    for i in range(period,len(signal)):\n",
    "        buffer.append(signal[i-period:i].mean())\n",
    "    return np.array(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 500.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length = 100\n",
    "avg_scores = moving_average(score_hist, length)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(avg_scores, label='avg_scores')\n",
    "plt.hlines(30, xmin=0, xmax=500, colors='r', label='solved')\n",
    "plt.grid()\n",
    "plt.xlabel('#Episode')\n",
    "plt.ylabel('Avg. score')\n",
    "plt.title(f'Avg. score over {length} episodes')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim((0, 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save My Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def save_agent(agent, avg_scores=None):\n",
    "    \"\"\"Saves the agent's parameters and the underlying pytorch model\"\"\"\n",
    "    checkpoint = {'actor_state_dict': agent.actor_local.state_dict(),\n",
    "                  'critic_state_dict': agent.critic_local.state_dict(),\n",
    "                  'score_hist': score_hist}\n",
    "            \n",
    "    torch.save(checkpoint, 'my_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_agent(agent, avg_scores=avg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
